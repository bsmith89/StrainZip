{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.genmod.families.links import Link, Log as LogLink\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import strainzip as sz\n",
    "import seaborn as sns\n",
    "\n",
    "from strainzip import model_zoo\n",
    "import strainzip as sz\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sz.model_zoo.multiplicative_gaussian_noise\n",
    "seed = 0\n",
    "alpha = 1e-0  # Small offset for handling 0s in depths\n",
    "n, m = 3, 4  # In-edges / out-edges\n",
    "s_samples = 4\n",
    "sigma = 1e-1  # Scale of the multiplicative noise\n",
    "depth_multiplier = 1  # Scaling factor for depths\n",
    "num_excess_paths = 1  # How many extra paths to include beyond correct ones.\n",
    "\n",
    "np.random.seed(seed)\n",
    "\n",
    "r_edges, p_paths = (n + m, n * m)\n",
    "X = sz.deconvolution.design_paths(n, m)[0].T\n",
    "assert X.shape == (r_edges, p_paths)\n",
    "\n",
    "# Select which pairs of in/out edges are \"real\" and assign them weights across samples.\n",
    "active_paths = sz.deconvolution.simulate_active_paths(n, m, excess=num_excess_paths)\n",
    "active_paths = [i for i, _ in active_paths]\n",
    "print(active_paths)\n",
    "beta = np.zeros((p_paths, s_samples))\n",
    "beta[active_paths, :] = np.random.lognormal(\n",
    "    mean=-5, sigma=7, size=(len(active_paths), s_samples)\n",
    ")\n",
    "beta = beta.round(1)  # Structural zeros\n",
    "\n",
    "\n",
    "# Simulate the observed depth of each edge.\n",
    "expect = X @ (beta * depth_multiplier)\n",
    "log_noise = np.random.normal(loc=0, scale=1, size=expect.shape)\n",
    "y_obs = expect * np.exp(log_noise * sigma)\n",
    "\n",
    "\n",
    "print(-model.negloglik(beta, sigma, y_obs, X, alpha=alpha))\n",
    "\n",
    "# # Simulate a selection of paths during the estimation procedure.\n",
    "# # Possibly over-specified. (see `num_excess_paths`)\n",
    "# _active_paths = list(\n",
    "#     sorted(\n",
    "#         set(active_paths)\n",
    "#         | set(\n",
    "#             np.random.choice(\n",
    "#                 [p for p in range(p_paths) if p not in active_paths],\n",
    "#                 replace=False,\n",
    "#                 size=num_excess_paths,\n",
    "#             )\n",
    "#         )\n",
    "#     )\n",
    "# )\n",
    "# X_reduced = X[:, _active_paths]\n",
    "\n",
    "# # Estimate model parameters\n",
    "# beta_est, sigma_est, _ = model.fit(y_obs, X_reduced, alpha=alpha)\n",
    "\n",
    "# # Calculate likelihood\n",
    "# loglik = -model.negloglik(beta_est, sigma_est, y_obs, X_reduced, alpha=alpha)\n",
    "# assert np.isfinite(loglik)\n",
    "\n",
    "# # Estimate standard errors.\n",
    "# beta_stderr, sigma_stderr = model.estimate_stderr(\n",
    "#     y_obs, X_reduced, beta_est, sigma_est, alpha=alpha\n",
    "# )\n",
    "\n",
    "# # Check model identifiable.\n",
    "# assert np.isfinite(beta_stderr).all()\n",
    "# assert np.isfinite(sigma_stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(pd.DataFrame(beta[active_paths, :], index=active_paths), norm=mpl.colors.SymLogNorm(1, vmin=-5e7, vmax=5e7), yticklabels=1, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_paths, beta_est, beta_stderr, sigma_est, sigma_stderr, inv_hessian, fit = (\n",
    "    sz.deconvolution.estimate_paths(\n",
    "        X,\n",
    "        y_obs,\n",
    "        model=sz.model_zoo.multiplicative_gaussian_noise,\n",
    "        forward_stop=0.2,\n",
    "        backward_stop=0.01,\n",
    "        verbose=2,\n",
    "        alpha=alpha)\n",
    ")\n",
    "print(set(selected_paths) - set(active_paths), set(selected_paths) & set(active_paths), set(active_paths) - set(selected_paths), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_paths = list(sorted(set(selected_paths) | set(active_paths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_est = pd.DataFrame(beta_est, index=selected_paths).reindex(all_paths, fill_value=0)\n",
    "sns.heatmap(depth_est, norm=mpl.colors.SymLogNorm(1, vmin=-5e7, vmax=5e7), yticklabels=1, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = pd.DataFrame(beta[active_paths, :], index=active_paths).reindex(all_paths, fill_value=0)\n",
    "sns.heatmap(depth, norm=mpl.colors.SymLogNorm(1, vmin=-5e7, vmax=5e7), yticklabels=1, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = depth_est - depth\n",
    "sns.heatmap(err, norm=mpl.colors.SymLogNorm(1, vmin=-5e7, vmax=5e7), yticklabels=1, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_est = pd.DataFrame(beta_stderr, index=selected_paths).reindex(all_paths, fill_value=0)\n",
    "sns.heatmap(err_est, norm=mpl.colors.SymLogNorm(1, vmin=-5e7, vmax=5e7), yticklabels=1, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.DataFrame(dict(\n",
    "    depth=depth.stack(),\n",
    "    depth_est=depth_est.stack(),\n",
    "    err=err.stack(),\n",
    "    stderr_est=err_est.stack(),\n",
    ")).rename_axis(['path', 'sample']).reset_index().assign(\n",
    "    false_positive=lambda x: x.path.isin(set(selected_paths) - set(active_paths)),\n",
    "    false_negative=lambda x: x.path.isin(set(active_paths) - set(selected_paths)),\n",
    ")\n",
    "xx = np.logspace(-1, 5)\n",
    "\n",
    "plt.scatter('depth', 'err', data=d, c='false_positive')\n",
    "plt.plot(xx, xx)\n",
    "plt.plot(xx, -xx)\n",
    "plt.xscale('symlog', linthresh=1e-1)\n",
    "plt.yscale('symlog', linthresh=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.DataFrame(dict(\n",
    "    depth=depth.stack(),\n",
    "    depth_est=depth_est.stack(),\n",
    "    err=err.stack(),\n",
    "    stderr_est=err_est.stack(),\n",
    ")).rename_axis(['path', 'sample']).reset_index().assign(\n",
    "    false_positive=lambda x: x.path.isin(set(selected_paths) - set(active_paths)),\n",
    "    false_negative=lambda x: x.path.isin(set(active_paths) - set(selected_paths)),\n",
    ")\n",
    "xx = np.logspace(-1, 3)\n",
    "\n",
    "plt.scatter('stderr_est', 'err', data=d)\n",
    "plt.plot(xx, xx)\n",
    "plt.plot(xx, -xx)\n",
    "plt.xscale('symlog', linthresh=1e-1)\n",
    "plt.yscale('symlog', linthresh=1e-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Known Specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_already_active_paths = [2, 4, 6]\n",
    "_active_paths = _already_active_paths\n",
    "\n",
    "X_reduced = X[:, _active_paths]\n",
    "# Estimate model parameters\n",
    "beta_reduced_est, sigma_est, _ = model.fit(\n",
    "    y_obs, X_reduced, alpha=alpha\n",
    ")\n",
    "loglik = -model.negloglik(\n",
    "    beta_reduced_est, sigma_est, y_obs, X_reduced, alpha=alpha\n",
    ")\n",
    "print(loglik, _active_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locally Better Set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (p, l) in enumerate(sz.deconvolution.iter_forward_greedy_path_selection(X, y_obs, sz.model_zoo.multiplicative_gaussian_noise, active_paths=active_paths, alpha=1.0)):\n",
    "    print(round(l, 0), p)\n",
    "    if i >= 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (p, l) in enumerate(sz.deconvolution.iter_backward_greedy_path_selection(X, y_obs, sz.model_zoo.multiplicative_gaussian_noise, active_paths=active_paths, alpha=1.0)):\n",
    "    print(round(l, 0), p)\n",
    "    if i >= 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greedy selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_l = float('-inf')\n",
    "\n",
    "for i, (p, l) in enumerate(sz.deconvolution.iter_forward_greedy_path_selection(X, y_obs, sz.model_zoo.multiplicative_gaussian_noise, active_paths=[], alpha=1.0)):\n",
    "    pvalue = sz.deconvolution.likelihood_ratio_test(l - prior_l, delta_df=s_samples)\n",
    "    print(round(l, 0), p, pvalue)\n",
    "    prior_l = l\n",
    "    if i >= 16:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_l = float('-inf')\n",
    "\n",
    "for i, (p, l) in enumerate(sz.deconvolution.iter_backward_greedy_path_selection(X, y_obs, sz.model_zoo.multiplicative_gaussian_noise, active_paths=[1, 2, 3, 4, 6, 8], alpha=1.0)):\n",
    "    pvalue = sz.deconvolution.likelihood_ratio_test(prior_l - l, delta_df=s_samples)\n",
    "    print(round(l, 0), p, pvalue)\n",
    "    prior_l = l\n",
    "    if i >= 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class Log1pLink(Link):\n",
    "    \"\"\"\n",
    "    Custom link function for log(1 + p).\n",
    "    \"\"\"    \n",
    "    def __init__(self):\n",
    "        super(Log1pLink, self).__init__()\n",
    "    \n",
    "    def __call__(self, p):\n",
    "        # The link function itself\n",
    "        return np.log(1 + p)\n",
    "\n",
    "    def inverse(self, z):\n",
    "        # The inverse of the link function\n",
    "        return np.exp(z) - 1\n",
    "\n",
    "    def deriv(self, p):\n",
    "        # Derivative of the link function\n",
    "        return 1 / (1 + p)\n",
    "\n",
    "    def inverse_deriv(self, z):\n",
    "        # Derivative of the inverse of the link function\n",
    "        return np.exp(z)\n",
    "\n",
    "    linkclass = property(lambda self: type(self).__name__)\n",
    "\n",
    "\n",
    "class Gaussian2(sm.families.Gaussian):\n",
    "    links = [Log1pLink]\n",
    "    safe_links = links\n",
    "\n",
    "LOG1PLINK = Log1pLink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import strainzip as sz\n",
    "import jax.numpy as jnp\n",
    "from jax import grad, hessian\n",
    "from jax.tree_util import Partial\n",
    "import jaxopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, m = 3, 3\n",
    "s_samples = 3\n",
    "r_edges, p_paths = (n+m, n*m)\n",
    "\n",
    "\n",
    "X = sz.deconvolution.design_paths(n, m)[0].T\n",
    "assert X.shape == (r_edges, p_paths)\n",
    "\n",
    "sns.heatmap(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "active_paths = simulate_active_paths(n, m)\n",
    "print(active_paths)\n",
    "active_paths = [i for i, _ in active_paths]\n",
    "\n",
    "beta = np.zeros((p_paths, s_samples))\n",
    "beta[active_paths, :] = np.random.lognormal(mean=-3, sigma=6, size=(len(active_paths), s_samples))\n",
    "# beta = beta.round(1)\n",
    "\n",
    "sns.heatmap(beta, norm=mpl.colors.SymLogNorm(1e-5))\n",
    "# sns.heatmap(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 1\n",
    "depth_multiplier = 1\n",
    "\n",
    "np.random.seed(2)\n",
    "expect = X @ (beta * depth_multiplier)\n",
    "log_noise = np.random.normal(loc=0, scale=1, size=expect.shape)\n",
    "y_obs = expect * np.exp(log_noise * sigma)\n",
    "\n",
    "# sns.heatmap(y_obs)\n",
    "sns.heatmap(y_obs, norm=mpl.colors.SymLogNorm(1e-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(4)\n",
    "\n",
    "num_excess_paths = 0\n",
    "_active_paths = list(sorted(set(active_paths) | set(np.random.choice([p for p in range(p_paths) if p not in active_paths], replace=False, size=num_excess_paths))))\n",
    "p_reduced = len(_active_paths)\n",
    "\n",
    "X_reduced = X[:, _active_paths]\n",
    "print(X_reduced.shape)\n",
    "\n",
    "sns.heatmap(X_reduced)\n",
    "print(np.linalg.matrix_rank(X_reduced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_est, sigma_est, fit = fit_model(y_obs, X_reduced, alpha=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hessian = hessian(Partial(model_loss, y=y_obs, X=X_reduced, alpha=1e-5), argnums=[0, 1])\n",
    "(_beta_beta_hess, _beta_sigma_hess), (_sigm_beta_hess, _sigma_sigma_hess) = model_hessian(beta_est, sigma_est)\n",
    "_hess_flat = _beta_beta_hess.reshape((p_reduced*s_samples, -1))\n",
    "_var_covar_matrix = jnp.linalg.inv(_hess_flat)\n",
    "_max = np.abs(_var_covar_matrix).max()\n",
    "\n",
    "_variance = np.diag(_var_covar_matrix).reshape((p_reduced, s_samples))\n",
    "_stderr = np.sqrt(_variance)\n",
    "assert np.isfinite(_stderr).all()\n",
    "\n",
    "# sns.heatmap(_var_covar_matrix, norm=mpl.colors.SymLogNorm(1, vmin=-_max, vmax=_max), cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(_hess_flat.shape)\n",
    "print(np.linalg.matrix_rank(_hess_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, s_samples, sharex=True, sharey=True, figsize=(3 * s_samples, 3))\n",
    "\n",
    "for s, ax in enumerate(axs):\n",
    "    ax.errorbar(beta[_active_paths, s].ravel(), beta_est[:, s], yerr=_stderr[:, s], fmt='.')\n",
    "    ax.plot([0, 2000], [0, 2000], lw=1, linestyle='--', color='k')\n",
    "\n",
    "plt.yscale('symlog', linthresh=1e-1)\n",
    "plt.xscale('symlog', linthresh=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "hess = hessian(Partial(loss, y=y_obs, X=X_reduced, eps=eps))(fit.params)\n",
    "hess_flat = hess.reshape((p_reduced*s_samples, p_reduced*s_samples))\n",
    "var_covar_matrix = jnp.linalg.inv(hess_flat)\n",
    "\n",
    "_max = np.abs(var_covar_matrix).max()\n",
    "\n",
    "# plt.plot(np.sqrt(np.diag(var_covar_matrix)), label='stderr')\n",
    "plt.plot(inv_trsfm_depth(fit.params, eps=eps).ravel(), label='estimate')\n",
    "# plt.plot(np.sqrt(np.diag(var_covar_matrix)) / fit.params.ravel(), label='cv')\n",
    "plt.plot(beta[_active_paths, :].ravel(), lw=1, linestyle='--', color='k', label='true')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.heatmap(var_covar_matrix, norm=mpl.colors.SymLogNorm(1, vmin=-_max, vmax=_max), cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "X = np.array([\n",
    "    [1, 1, 1, 0, 0, 0],\n",
    "    [0, 0, 0, 1, 1, 1],\n",
    "    [1, 0, 0, 1, 0, 0],\n",
    "    [0, 1, 0, 0, 1, 0],\n",
    "    [0, 0, 1, 0, 0, 1],\n",
    "])\n",
    "\n",
    "# Latent path depths\n",
    "beta = np.array([\n",
    "    [1. , 1. , 0. ],\n",
    "    [1. , 0. , 0. ],\n",
    "    [0. , 0. , 0. ],\n",
    "    [0. , 0. , 0. ],\n",
    "    [0. , 0. , 0. ],\n",
    "    [1. , 0. , 1. ],\n",
    "]) * 10000\n",
    "# beta = np.array([\n",
    "#     [1.],\n",
    "#     [0.5],\n",
    "#     [0.],\n",
    "#     [0.],\n",
    "#     [0.],\n",
    "#     [0.],\n",
    "# ])\n",
    "\n",
    "n, m = 2, 3\n",
    "\n",
    "\n",
    "s_samples = beta.shape[1]\n",
    "p_paths = X.shape[1]\n",
    "r_edges = X.shape[0]\n",
    "\n",
    "assert X.shape == (n+m, n*m)\n",
    "assert beta.shape == (p_paths, s_samples)\n",
    "\n",
    "y = X @ beta\n",
    "y_obs = y * np.random.lognormal(0, sigma=2, size=y.shape)\n",
    "\n",
    "y_stacked = y.reshape((r_edges * s_samples, 1))\n",
    "\n",
    "y_stacked.shape\n",
    "X_stacked = np.block([[X] * s_samples] * s_samples)\n",
    "\n",
    "assert X_stacked.shape[0] == y_stacked.shape[0]\n",
    "\n",
    "# beta_stacked = beta.reshape((p_paths * s_samples, 1))\n",
    "\n",
    "# print(X_stacked.shape)\n",
    "# print(beta_stacked.shape)\n",
    "# print(y_stacked.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from functools import partial\n",
    "\n",
    "def loss(y, X, beta):\n",
    "    return np.sum((np.log(y + 1) - np.log(X @ beta + 1))**2)\n",
    "\n",
    "def _pack(beta):\n",
    "    p, s = beta.shape\n",
    "    return beta.ravel(), p, s\n",
    "\n",
    "def _unpack(packed, p, s):\n",
    "    beta = packed.reshape((p, s))\n",
    "    return beta\n",
    "\n",
    "def loss_packed(packed, y, X, p, s):\n",
    "    beta = _unpack(packed, p, s)\n",
    "    return loss(y, X, beta)\n",
    "\n",
    "active_paths = [0, 1, 5]\n",
    "reduced_X = X[:, active_paths]\n",
    "reduced_p = len(active_paths)\n",
    "\n",
    "# packed, p, s = _pack(beta)\n",
    "# loss_packed(packed, y, X, p, s)\n",
    "_fun = partial(loss_packed, y=y, X=reduced_X, p=reduced_p, s=s_samples)\n",
    "\n",
    "result = sp.optimize.minimize(_fun, x0=np.random.lognormal(size=reduced_p*s_samples), bounds=[(0, None)] * (reduced_p * s_samples))\n",
    "_unpack(result.x, reduced_p, s_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import grad, hessian\n",
    "from jax.tree_util import Partial\n",
    "\n",
    "eps = 1\n",
    "\n",
    "def trsfm_depth(beta, eps):\n",
    "    return jnp.log(beta + eps)\n",
    "\n",
    "def inv_trsfm_depth(trsfm_beta, eps):\n",
    "    return jnp.exp(trsfm_beta) - eps\n",
    "\n",
    "def loss_(trsfm_beta, y, X, eps):\n",
    "    return jnp.sum((trsfm_depth(y, eps) - trsfm_depth(X @ inv_trsfm_depth(trsfm_beta, eps), eps))**2)\n",
    "\n",
    "active_paths = [0,1,5]\n",
    "reduced_X = X[:, active_paths]\n",
    "trsfm_reduced_beta = trsfm_depth(beta[active_paths, :], eps)\n",
    "p_reduced = len(active_paths)\n",
    "\n",
    "# loss = Partial(loss_, y=y_obs, X=reduced_X, eps=eps)\n",
    "# grad_loss = grad(loss)\n",
    "# hess_loss = hessian(loss)\n",
    "\n",
    "# loss(trsfm_reduced_beta), grad_loss(trsfm_reduced_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pack(beta):\n",
    "    p, s = beta.shape\n",
    "    return beta.ravel(), p, s\n",
    "\n",
    "def _unpack(packed, p, s):\n",
    "    beta = packed.reshape((p, s))\n",
    "    return beta\n",
    "\n",
    "def _loss_packed(packed, y, X, eps, p, s):\n",
    "    trsfm_beta = _unpack(packed, p, s)\n",
    "    return loss_(trsfm_beta, y, X, eps)\n",
    "\n",
    "loss = Partial(_loss_packed, y=y_obs, X=reduced_X, eps=eps, p=p_reduced, s=s_samples)\n",
    "grad_loss = grad(loss)\n",
    "hess_loss = hessian(loss)\n",
    "\n",
    "res = sp.optimize.minimize(loss, x0=np.zeros(p_reduced*s_samples), jac=grad_loss)\n",
    "est_beta_reduced = res.x\n",
    "inv_trsfm_depth(_unpack(est_beta_reduced, p=p_reduced, s=s_samples), eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_unpack(est_beta_reduced, p=p_reduced, s=s_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_unpack(grad_loss(est_beta_reduced), p=p_reduced, s=s_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_this_hessian = hess_loss(est_beta_reduced)\n",
    "var_covar_matrix = jnp.linalg.inv(_this_hessian)\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(var_covar_matrix, center=0)\n",
    "\n",
    "print(np.sqrt(_unpack(np.diag(var_covar_matrix), p=p_reduced, s=s_samples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hess_loss(sol.params).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_paths = [0, 1]\n",
    "reduced_X = X[:, active_paths]\n",
    "reduced_X_stacked = np.block([[reduced_X] * s_samples] * s_samples)\n",
    "\n",
    "model = sm.GLM(LOG1PLINK(y_stacked * 100000), reduced_X_stacked, family=Gaussian2(link=Log1pLink()))\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc as pm\n",
    "import pytensor.tensor as tt\n",
    "\n",
    "def log1p_np(x):\n",
    "    return np.log(x + 1)\n",
    "\n",
    "def log1p_pm(x):\n",
    "    return tt.log(x + 1)\n",
    "\n",
    "active_paths = [0,1,4,5]\n",
    "reduced_X = X[:, active_paths]\n",
    "\n",
    "y_obs = X @ (beta * 100)\n",
    "\n",
    "with pm.Model() as model0:\n",
    "    design = pm.Data('design', value=reduced_X, shape=(r_edges, len(active_paths)), mutable=True)\n",
    "    observed_trsfm = pm.Data('observed', value=log1p_np(y_obs), shape=(r_edges, s_samples), mutable=True)\n",
    "    b = pm.LogNormal('b', shape=(len(active_paths), s_samples))\n",
    "    s = pm.LogNormal('s', mu=-2, sigma=1)\n",
    "    expect = design @ b\n",
    "    lik = pm.Normal('lik', mu=log1p_pm(expect), sigma=s, observed=observed_trsfm)\n",
    "\n",
    "    trace = pm.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.summary(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.GLM(y_stacked, X_stacked, family=sm.families.Gaussian(link=LogLink()))\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_paths = [0,1,4,5]\n",
    "reduced_X = X[:, active_paths]\n",
    "reduced_X_stacked = np.block([[reduced_X] * s_samples] * s_samples)\n",
    "\n",
    "model = sm.GLM(y_stacked, reduced_X_stacked, family=sm.families.Gaussian(link=LogLink()))\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_paths = [1,4,5]\n",
    "reduced_X = X[:, active_paths]\n",
    "reduced_X_stacked = np.block([[reduced_X] * s_samples] * s_samples)\n",
    "\n",
    "model = sm.GLM(LOG1PLINK(y_stacked), reduced_X_stacked, family=Gaussian2(link=Log1pLink()))\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_paths = [0, 1, 2, 4, 5]\n",
    "reduced_X = X[:, active_paths]\n",
    "reduced_X_stacked = np.block([[reduced_X] * s_samples] * s_samples)\n",
    "\n",
    "model = sm.GLM(LOG1PLINK(y_stacked), reduced_X_stacked, family=Gaussian2(link=Log1pLink()))\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_paths = [1, 2, 4, 5]\n",
    "reduced_X = X[:, active_paths]\n",
    "reduced_X_stacked = np.block([[reduced_X] * s_samples] * s_samples)\n",
    "\n",
    "model = sm.GLM(LOG1PLINK(y_stacked), reduced_X_stacked, family=Gaussian2(link=Log1pLink()))\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_paths = [4, 5]\n",
    "reduced_X = X[:, active_paths]\n",
    "reduced_X_stacked = np.block([[reduced_X] * s_samples] * s_samples)\n",
    "\n",
    "model = sm.GLM(LOG1PLINK(y_stacked), reduced_X_stacked, family=Gaussian2(link=Log1pLink()))\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "strainzip",
   "language": "python",
   "name": "strainzip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}