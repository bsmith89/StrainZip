{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.genmod.families.links import Link, Log as LogLink\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import strainzip as sz\n",
    "import seaborn as sns\n",
    "\n",
    "from strainzip import depth_model\n",
    "import strainzip as sz\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sz.depth_model\n",
    "seed = 0\n",
    "alpha = 1e-0  # Small offset for handling 0s in depths\n",
    "n, m = 3, 4  # In-edges / out-edges\n",
    "s_samples = 4\n",
    "sigma = 1e-1  # Scale of the multiplicative noise\n",
    "depth_multiplier = 1  # Scaling factor for depths\n",
    "num_excess_paths = 1  # How many extra paths to include beyond correct ones.\n",
    "\n",
    "np.random.seed(seed)\n",
    "\n",
    "r_edges, p_paths = (n + m, n * m)\n",
    "X = sz.deconvolution.design_paths(n, m)[0]\n",
    "assert X.shape == (r_edges, p_paths)\n",
    "\n",
    "# Select which pairs of in/out edges are \"real\" and assign them weights across samples.\n",
    "active_paths = sz.deconvolution.simulate_active_paths(n, m, excess=num_excess_paths)\n",
    "active_paths = [i for i, _ in active_paths]\n",
    "print(active_paths)\n",
    "beta = np.zeros((p_paths, s_samples))\n",
    "beta[active_paths, :] = np.random.lognormal(\n",
    "    mean=-5, sigma=7, size=(len(active_paths), s_samples)\n",
    ")\n",
    "beta = beta.round(1)  # Structural zeros\n",
    "\n",
    "\n",
    "# Simulate the observed depth of each edge.\n",
    "expect = X @ (beta * depth_multiplier)\n",
    "log_noise = np.random.normal(loc=0, scale=1, size=expect.shape)\n",
    "y_obs = expect * np.exp(log_noise * sigma)\n",
    "\n",
    "\n",
    "print(-model.negloglik(beta, sigma, y_obs, X, alpha=alpha))\n",
    "\n",
    "# # Simulate a selection of paths during the estimation procedure.\n",
    "# # Possibly over-specified. (see `num_excess_paths`)\n",
    "# _active_paths = list(\n",
    "#     sorted(\n",
    "#         set(active_paths)\n",
    "#         | set(\n",
    "#             np.random.choice(\n",
    "#                 [p for p in range(p_paths) if p not in active_paths],\n",
    "#                 replace=False,\n",
    "#                 size=num_excess_paths,\n",
    "#             )\n",
    "#         )\n",
    "#     )\n",
    "# )\n",
    "# X_reduced = X[:, _active_paths]\n",
    "\n",
    "# # Estimate model parameters\n",
    "# beta_est, sigma_est, _ = model.fit(y_obs, X_reduced, alpha=alpha)\n",
    "\n",
    "# # Calculate likelihood\n",
    "# loglik = -model.negloglik(beta_est, sigma_est, y_obs, X_reduced, alpha=alpha)\n",
    "# assert np.isfinite(loglik)\n",
    "\n",
    "# # Estimate standard errors.\n",
    "# beta_stderr, sigma_stderr = model.estimate_stderr(\n",
    "#     y_obs, X_reduced, beta_est, sigma_est, alpha=alpha\n",
    "# )\n",
    "\n",
    "# # Check model identifiable.\n",
    "# assert np.isfinite(beta_stderr).all()\n",
    "# assert np.isfinite(sigma_stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(pd.DataFrame(beta[active_paths, :], index=active_paths), norm=mpl.colors.SymLogNorm(1, vmin=-5e7, vmax=5e7), yticklabels=1, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_paths, beta_est, beta_stderr, sigma_est, sigma_stderr, inv_hessian, fit, delta_aic = (\n",
    "    sz.deconvolution.estimate_paths(\n",
    "        X,\n",
    "        y_obs,\n",
    "        model=sz.depth_model,\n",
    "        forward_stop=0.2,\n",
    "        backward_stop=0.01,\n",
    "        verbose=2,\n",
    "        alpha=alpha,\n",
    "    )\n",
    ")\n",
    "print(set(selected_paths) - set(active_paths), set(selected_paths) & set(active_paths), set(active_paths) - set(selected_paths), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_aic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_paths = list(sorted(set(selected_paths) | set(active_paths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_est = pd.DataFrame(beta_est, index=selected_paths).reindex(all_paths, fill_value=0)\n",
    "sns.heatmap(depth_est, norm=mpl.colors.SymLogNorm(1, vmin=-5e7, vmax=5e7), yticklabels=1, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = pd.DataFrame(beta[active_paths, :], index=active_paths).reindex(all_paths, fill_value=0)\n",
    "sns.heatmap(depth, norm=mpl.colors.SymLogNorm(1, vmin=-5e7, vmax=5e7), yticklabels=1, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = depth_est - depth\n",
    "sns.heatmap(err, norm=mpl.colors.SymLogNorm(1, vmin=-5e7, vmax=5e7), yticklabels=1, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_est = pd.DataFrame(beta_stderr, index=selected_paths).reindex(all_paths, fill_value=0)\n",
    "sns.heatmap(err_est, norm=mpl.colors.SymLogNorm(1, vmin=-5e7, vmax=5e7), yticklabels=1, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.DataFrame(dict(\n",
    "    depth=depth.stack(),\n",
    "    depth_est=depth_est.stack(),\n",
    "    err=err.stack(),\n",
    "    stderr_est=err_est.stack(),\n",
    ")).rename_axis(['path', 'sample']).reset_index().assign(\n",
    "    false_positive=lambda x: x.path.isin(set(selected_paths) - set(active_paths)),\n",
    "    false_negative=lambda x: x.path.isin(set(active_paths) - set(selected_paths)),\n",
    ")\n",
    "xx = np.logspace(-1, 5)\n",
    "\n",
    "plt.scatter('depth', 'err', data=d, c='false_positive')\n",
    "plt.plot(xx, xx)\n",
    "plt.plot(xx, -xx)\n",
    "plt.xscale('symlog', linthresh=1e-1)\n",
    "plt.yscale('symlog', linthresh=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.DataFrame(dict(\n",
    "    depth=depth.stack(),\n",
    "    depth_est=depth_est.stack(),\n",
    "    err=err.stack(),\n",
    "    stderr_est=err_est.stack(),\n",
    ")).rename_axis(['path', 'sample']).reset_index().assign(\n",
    "    false_positive=lambda x: x.path.isin(set(selected_paths) - set(active_paths)),\n",
    "    false_negative=lambda x: x.path.isin(set(active_paths) - set(selected_paths)),\n",
    ")\n",
    "xx = np.logspace(-1, 3)\n",
    "\n",
    "plt.scatter('stderr_est', 'err', data=d)\n",
    "plt.plot(xx, xx)\n",
    "plt.plot(xx, -xx)\n",
    "plt.xscale('symlog', linthresh=1e-1)\n",
    "plt.yscale('symlog', linthresh=1e-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "strainzip",
   "language": "python",
   "name": "strainzip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}