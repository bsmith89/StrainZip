{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os as _os\n",
    "_os.chdir(_os.environ['PROJECT_ROOT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import strainzip as sz\n",
    "import graph_tool as gt\n",
    "import graph_tool.draw\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from contextlib import contextmanager\n",
    "import xarray as xr\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from strainzip.pandas_util import idxwhere\n",
    "from graph_tool.util import find_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_bins = np.logspace(0, 6.5, num=51)\n",
    "depth_bins = np.logspace(-1, 4, num=51)\n",
    "\n",
    "k = 111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load depth data\n",
    "depth_table = xr.load_dataarray(f'examples/xjin_test4/r.proc.kmtricks-k{k}-m3-r2.ggcat.unitig_depth.nc')\n",
    "depth_table.sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'examples/xjin_test4/r.proc.kmtricks-k{k}-m3-r2.ggcat.fn') as f:\n",
    "    _, seqs = sz.io.load_graph_and_sequences_from_linked_fasta(f, k=k, header_tokenizer=sz.io.ggcat_header_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load graph\n",
    "graph = sz.io.load_graph(f'examples/xjin_test4/r.proc.kmtricks-k{k}-m3-r2.ggcat.gt')\n",
    "# FIXME: These annotations should go into the loading app:\n",
    "graph.gp['num_samples'] = graph.new_graph_property('int', val=depth_table.sizes['sample'])\n",
    "graph.gp['kmer_length'] = graph.new_graph_property('int', val=k)\n",
    "\n",
    "# Set depth on graph\n",
    "vertex_unitig_order = [int(s[:-1]) for s in graph.vp['sequence']]\n",
    "graph.vp['depth'] = graph.new_vertex_property('vector<float>')\n",
    "graph.vp['depth'].set_2d_array(depth_table.sel(unitig=vertex_unitig_order).T.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select components in a deterministic way (from largest to smallest).\n",
    "\n",
    "component_graphs = []\n",
    "\n",
    "graph_remaining = graph.new_vertex_property('bool', val=True)\n",
    "\n",
    "last_graph_size = 1_000_000\n",
    "while last_graph_size > 1000:\n",
    "    this_component = gt.topology.label_largest_component(gt.GraphView(graph, vfilt=graph_remaining), directed=False)\n",
    "    component_graphs.append(gt.GraphView(graph, vfilt=this_component))\n",
    "    graph_remaining = graph.new_vertex_property('bool', vals=graph_remaining.a - this_component.a)\n",
    "    last_graph_size = this_component.a.sum()\n",
    "\n",
    "len(component_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The largest components has a huge fraction of the unitigs\n",
    "component_graphs[0], component_graphs[1], component_graphs[2], component_graphs[3], component_graphs[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "\n",
    "draw_graphs = False\n",
    "\n",
    "# component = c\n",
    "component = 16  # Only the label for plotting\n",
    "\n",
    "graph2 = gt.Graph(component_graphs[c], prune=True)\n",
    "# graph2.ep['filter'] = graph2.new_edge_property('bool',   # TODO: Think about filtering edges instead of removing them entirely.\n",
    "graph2.set_vertex_filter(graph2.vp['filter'])\n",
    "\n",
    "np.random.seed(1)\n",
    "gt.seed_rng(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if draw_graphs:\n",
    "    total_bases = graph2.new_vertex_property('float', vals=graph2.vp.length.fa * graph2.vp.depth.get_2d_array(pos=range(graph2.gp['num_samples'])).sum(0))\n",
    "    sz.draw.update_xypositions(graph2, vweight=total_bases)\n",
    "    gm = sz.graph_manager.GraphManager(\n",
    "        unzippers=[\n",
    "            sz.graph_manager.LengthUnzipper(),\n",
    "            sz.graph_manager.SequenceUnzipper(),\n",
    "            sz.graph_manager.VectorDepthUnzipper(),\n",
    "            sz.graph_manager.PositionUnzipper(offset=(0.1, 0.1)),\n",
    "        ],\n",
    "        pressers=[\n",
    "            sz.graph_manager.LengthPresser(),\n",
    "            sz.graph_manager.SequencePresser(sep=\",\"),\n",
    "            sz.graph_manager.VectorDepthPresser(),\n",
    "            sz.graph_manager.PositionPresser(),\n",
    "        ],\n",
    "    )\n",
    "else:\n",
    "    gm = sz.graph_manager.GraphManager(\n",
    "        unzippers=[\n",
    "            sz.graph_manager.LengthUnzipper(),\n",
    "            sz.graph_manager.SequenceUnzipper(),\n",
    "            sz.graph_manager.VectorDepthUnzipper(),\n",
    "        ],\n",
    "        pressers=[\n",
    "            sz.graph_manager.LengthPresser(),\n",
    "            sz.graph_manager.SequencePresser(sep=\",\"),\n",
    "            sz.graph_manager.VectorDepthPresser(),\n",
    "        ],\n",
    "    )\n",
    "gm.validate(graph2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph3 = graph2.copy()  # Save for later plotting\n",
    "sz.stats.degree_stats(graph3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembly_stage = 0\n",
    "\n",
    "# Calculate Flows\n",
    "flow = []\n",
    "for sample_id in range(graph2.gp['num_samples']):\n",
    "    one_flow, _, _, = sz.flow.estimate_flow(graph2, gt.ungroup_vector_property(graph2.vp['depth'], pos=[sample_id])[0], graph2.vp['length'])\n",
    "    flow.append(one_flow)\n",
    "flow = gt.group_vector_property(flow, pos=range(graph2.gp['num_samples']))\n",
    "\n",
    "# Initial depths\n",
    "plt.hist2d(\n",
    "    graph2.vp['length'].fa,\n",
    "    graph2.vp['depth'].get_2d_array(range(graph2.gp['num_samples'])).sum(0),\n",
    "    bins=(length_bins, depth_bins),\n",
    "    norm=mpl.colors.LogNorm(vmin=1, vmax=1e3),\n",
    ")\n",
    "plt.colorbar()\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.savefig(f'nb/fig/component-{component}/hist_stage{assembly_stage}.pdf')\n",
    "\n",
    "if draw_graphs:\n",
    "    # Update positions\n",
    "    total_bases = graph2.new_vertex_property('float', vals=graph2.vp.length.fa * graph2.vp.depth.get_2d_array(pos=range(graph2.gp['num_samples'])).sum(0))\n",
    "    # sz.draw.update_xypositions(graph2, vweight=total_bases, max_iter=100, init_step=1)\n",
    "\n",
    "    _color = graph2.new_vertex_property('float', vals=graph2.vp['depth'].get_2d_array(range(graph2.gp['num_samples'])).sum(0) ** (1/2))\n",
    "    _width = graph2.new_edge_property('float', vals=flow.get_2d_array(range(graph2.gp['num_samples'])).sum(0) ** (1/2) / 2)\n",
    "    sz.draw.draw_graph(\n",
    "        graph2,\n",
    "        vertex_text=graph2.vp['length'],\n",
    "        vertex_fill_color=_color,\n",
    "        # edge_color=flow,\n",
    "        # edge_pen_width=_width,\n",
    "        output=f'nb/fig/component-{component}/graph_stage{assembly_stage}.pdf',\n",
    "        vcmap=(mpl.cm.magma),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depth Smoothing\n",
    "\n",
    "smoothed_depths = []\n",
    "for i in range(graph2.gp['num_samples']):\n",
    "    one_depth = gt.ungroup_vector_property(graph2.vp.depth, pos=[i])[0]\n",
    "    smoothed, _change = sz.flow.smooth_depth(graph2, one_depth, graph2.vp.length, inertia=0.5, num_iter=50)\n",
    "    print(_change)\n",
    "    smoothed_depths.append(smoothed)\n",
    "\n",
    "smoothed_depths = gt.group_vector_property(smoothed_depths) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembly_stage = 1\n",
    "\n",
    "# Calculate Flows\n",
    "flow = []\n",
    "for sample_id in range(graph2.gp['num_samples']):\n",
    "    one_flow, _, _, = sz.flow.estimate_flow(graph2, gt.ungroup_vector_property(graph2.vp['depth'], pos=[sample_id])[0], graph2.vp['length'])\n",
    "    flow.append(one_flow)\n",
    "flow = gt.group_vector_property(flow, pos=range(graph2.gp['num_samples']))\n",
    "\n",
    "# Initial depths\n",
    "plt.hist2d(\n",
    "    graph2.vp['length'].fa,\n",
    "    graph2.vp['depth'].get_2d_array(range(graph2.gp['num_samples'])).sum(0),\n",
    "    bins=(length_bins, depth_bins),\n",
    "    norm=mpl.colors.LogNorm(vmin=1, vmax=1e3),\n",
    ")\n",
    "plt.colorbar()\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.savefig(f'nb/fig/component-{component}/hist_stage{assembly_stage}.pdf')\n",
    "\n",
    "if draw_graphs:\n",
    "    # Update positions\n",
    "    total_bases = graph2.new_vertex_property('float', vals=graph2.vp.length.fa * graph2.vp.depth.get_2d_array(pos=range(graph2.gp['num_samples'])).sum(0))\n",
    "    # sz.draw.update_xypositions(graph2, vweight=total_bases, max_iter=100, init_step=1)\n",
    "\n",
    "    _color = graph2.new_vertex_property('float', vals=graph2.vp['depth'].get_2d_array(range(graph2.gp['num_samples'])).sum(0) ** (1/2))\n",
    "    _width = graph2.new_edge_property('float', vals=flow.get_2d_array(range(graph2.gp['num_samples'])).sum(0) ** (1/2) / 2)\n",
    "    sz.draw.draw_graph(\n",
    "        graph2,\n",
    "        vertex_text=graph2.vp['length'],\n",
    "        vertex_fill_color=_color,\n",
    "        # edge_color=flow,\n",
    "        # edge_pen_width=_width,\n",
    "        output=f'nb/fig/component-{component}/graph_stage{assembly_stage}.pdf',\n",
    "        vcmap=(mpl.cm.magma),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actually push smoothed depths to the graph\n",
    "graph2.vp['depth'] = smoothed_depths  # TODO: Experiment with and without this.\n",
    "\n",
    "# FIXME: Long tips lose too much depth?\n",
    "# NOTE: It's possible that depth smoothing introduces artifacts at junctions that affects how they're split...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Consider dropping low depth vertices/edges\n",
    "# depth_thresh = 0.1\n",
    "# # Drop edges with low depth\n",
    "# low_depth_edge = graph2.new_edge_property('float', vals=flow.get_2d_array(pos=range(graph2.gp['num_samples'])).sum(0) < depth_thresh)\n",
    "# low_depth_edges = find_edge(graph2, low_depth_edge, True)\n",
    "# for e in low_depth_edges:\n",
    "#     graph2.remove_edge(e)\n",
    "# low_depth_vertices = idxwhere(sz.results.extract_vertex_data(graph2, seqs).total_depth < depth_thresh)\n",
    "# print(len(tips), len(low_depth_vertices), len(set(tips) & set(low_depth_vertices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim tips\n",
    "tips = sz.assembly.find_tips(graph2, also_required=graph2.vp['length'].a < graph2.gp['kmer_length'])\n",
    "print(len(tips))\n",
    "gm.batch_trim(graph2, tips)\n",
    "\n",
    "graph4 = graph2.copy()  # Save for later plotting\n",
    "\n",
    "_new_tigs = gm.batch_press(graph2, *[(path, {}) for path in sz.assembly.iter_maximal_unitig_paths(graph2)])\n",
    "len(_new_tigs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second round of tip trimming\n",
    "tips = sz.assembly.find_tips(graph2, also_required=graph2.vp['length'].a < graph2.gp['kmer_length'])\n",
    "print(len(tips))\n",
    "gm.batch_trim(graph2, tips)\n",
    "_new_tigs = gm.batch_press(graph2, *[(path, {}) for path in sz.assembly.iter_maximal_unitig_paths(graph2)])\n",
    "print(len(_new_tigs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz.stats.degree_stats(graph2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembly_stage = 2\n",
    "\n",
    "# Calculate Flows\n",
    "flow = []\n",
    "for sample_id in range(graph2.gp['num_samples']):\n",
    "    one_flow, _, _, = sz.flow.estimate_flow(graph2, gt.ungroup_vector_property(graph2.vp['depth'], pos=[sample_id])[0], graph2.vp['length'])\n",
    "    flow.append(one_flow)\n",
    "flow = gt.group_vector_property(flow, pos=range(graph2.gp['num_samples']))\n",
    "\n",
    "# Initial depths\n",
    "plt.hist2d(\n",
    "    graph2.vp['length'].fa,\n",
    "    graph2.vp['depth'].get_2d_array(range(graph2.gp['num_samples'])).sum(0),\n",
    "    bins=(length_bins, depth_bins),\n",
    "    norm=mpl.colors.LogNorm(vmin=1, vmax=1e3),\n",
    ")\n",
    "plt.colorbar()\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.savefig(f'nb/fig/component-{component}/hist_stage{assembly_stage}.pdf')\n",
    "\n",
    "if draw_graphs:\n",
    "    # Update positions\n",
    "    total_bases = graph2.new_vertex_property('float', vals=graph2.vp.length.fa * graph2.vp.depth.get_2d_array(pos=range(graph2.gp['num_samples'])).sum(0))\n",
    "    # sz.draw.update_xypositions(graph2, vweight=total_bases, max_iter=100, init_step=1)\n",
    "\n",
    "    _color = graph2.new_vertex_property('float', vals=graph2.vp['depth'].get_2d_array(range(graph2.gp['num_samples'])).sum(0) ** (1/2))\n",
    "    _width = graph2.new_edge_property('float', vals=flow.get_2d_array(range(graph2.gp['num_samples'])).sum(0) ** (1/2) / 2)\n",
    "    sz.draw.draw_graph(\n",
    "        graph2,\n",
    "        vertex_text=graph2.vp['length'],\n",
    "        vertex_fill_color=_color,\n",
    "        # edge_color=flow,\n",
    "        # edge_pen_width=_width,\n",
    "        output=f'nb/fig/component-{component}/graph_stage{assembly_stage}.pdf',\n",
    "        vcmap=(mpl.cm.magma),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "junctions = sz.assembly.find_junctions(graph2)\n",
    "print(len(junctions))\n",
    "\n",
    "batch = []\n",
    "for j in tqdm(junctions):\n",
    "    in_edge_vertices = [edge[0] for edge in graph2.get_in_edges(j)]\n",
    "    out_edge_vertices = [edge[1] for edge in graph2.get_out_edges(j)]\n",
    "    \n",
    "    in_edge_flows = np.stack([flow[edge] for edge in graph2.get_in_edges(j)])\n",
    "    out_edge_flows = np.stack([flow[edge] for edge in graph2.get_out_edges(j)])\n",
    "    log_offset_ratio = np.log(in_edge_flows.sum()) - np.log(out_edge_flows.sum())\n",
    "\n",
    "    # Balance flows before fitting.\n",
    "    in_edge_flows = np.exp(np.log(in_edge_flows) - log_offset_ratio / 2)\n",
    "    out_edge_flows = np.exp(np.log(out_edge_flows) + log_offset_ratio / 2)\n",
    "    \n",
    "    n, m = len(in_edge_vertices), len(out_edge_vertices)\n",
    "    if n * m > 20:\n",
    "        # print(f\"[junc={j} / {n}x{m}] Too many possible paths.\")\n",
    "        continue\n",
    "    X = sz.deconvolution.design_paths(n, m)[0]\n",
    "    fit, paths, named_paths, score_margin = sz.deconvolution.deconvolve_junction(\n",
    "        in_edge_vertices,\n",
    "        in_edge_flows,\n",
    "        out_edge_vertices,\n",
    "        out_edge_flows,\n",
    "        model=sz.depth_model,\n",
    "        forward_stop=0,\n",
    "        backward_stop=0,\n",
    "        alpha=1.,\n",
    "    )\n",
    "    if not (score_margin > 20):  # TODO: Consider selecting non-best models that have a small enough score margin, after using a more negative backward_stop threshold.\n",
    "        # print(f\"[junc={j} / {n}x{m}] Cannot pick best model. (Selected model had {len(paths)} paths; score margin: {score_margin})\")\n",
    "        pass\n",
    "    elif not X[:, paths].sum(1).min() == 1:\n",
    "        # print(f\"[junc={j} / {n}x{m}] Non-complete. (Best model had {len(paths)} paths; score margin: {score_margin})\")\n",
    "        pass\n",
    "    elif not len(paths) <= max(n, m):\n",
    "        # print(f\"[junc={j} / {n}x{m}] Non-minimal. (Best model had {len(paths)} paths; score margin: {score_margin})\")\n",
    "        pass\n",
    "    elif not (np.linalg.cond(fit.hessian_beta) < 1e5):\n",
    "        # print(f\"[junc={j} / {n}x{m}] Non-identifiable. (Best model had {len(paths)} paths; score margin: {score_margin})\")\n",
    "        pass\n",
    "    else:\n",
    "        # print(f\"[junc={j} / {n}x{m}] SUCCESS! Selected {len(paths)} paths; score margin: {score_margin}\")\n",
    "        batch.append((j, named_paths, {\"path_depths\": fit.beta.clip(0)}))\n",
    "\n",
    "print(len(batch) / len(junctions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_new_tigs = gm.batch_unzip(graph2, *batch)\n",
    "print(len(_new_tigs))\n",
    "\n",
    "_new_tigs = gm.batch_press(graph2, *[(path, {}) for path in sz.assembly.iter_maximal_unitig_paths(graph2)])\n",
    "len(_new_tigs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _new_tigs = gm.batch_press(graph2, *[(path, {}) for path in sz.assembly.iter_maximal_unitig_paths(graph2)])\n",
    "# len(_new_tigs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz.stats.degree_stats(graph2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembly_stage = 3\n",
    "\n",
    "# Calculate Flows\n",
    "flow = []\n",
    "for sample_id in range(graph2.gp['num_samples']):\n",
    "    one_flow, _, _, = sz.flow.estimate_flow(graph2, gt.ungroup_vector_property(graph2.vp['depth'], pos=[sample_id])[0], graph2.vp['length'])\n",
    "    flow.append(one_flow)\n",
    "flow = gt.group_vector_property(flow, pos=range(graph2.gp['num_samples']))\n",
    "\n",
    "# Initial depths\n",
    "plt.hist2d(\n",
    "    graph2.vp['length'].fa,\n",
    "    graph2.vp['depth'].get_2d_array(range(graph2.gp['num_samples'])).sum(0),\n",
    "    bins=(length_bins, depth_bins),\n",
    "    norm=mpl.colors.LogNorm(vmin=1, vmax=1e3),\n",
    ")\n",
    "plt.colorbar()\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.savefig(f'nb/fig/component-{component}/hist_stage{assembly_stage}.pdf')\n",
    "\n",
    "if draw_graphs:\n",
    "    # Update positions\n",
    "    total_bases = graph2.new_vertex_property('float', vals=graph2.vp.length.fa * graph2.vp.depth.get_2d_array(pos=range(graph2.gp['num_samples'])).sum(0))\n",
    "    # sz.draw.update_xypositions(graph2, vweight=total_bases, max_iter=100, init_step=1)\n",
    "\n",
    "    _color = graph2.new_vertex_property('float', vals=graph2.vp['depth'].get_2d_array(range(graph2.gp['num_samples'])).sum(0) ** (1/2))\n",
    "    _width = graph2.new_edge_property('float', vals=flow.get_2d_array(range(graph2.gp['num_samples'])).sum(0) ** (1/2) / 2)\n",
    "    sz.draw.draw_graph(\n",
    "        graph2,\n",
    "        vertex_text=graph2.vp['length'],\n",
    "        vertex_fill_color=_color,\n",
    "        # edge_color=flow,\n",
    "        # edge_pen_width=_width,\n",
    "        output=f'nb/fig/component-{component}/graph_stage{assembly_stage}.pdf',\n",
    "        vcmap=(mpl.cm.magma),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "junctions = sz.assembly.find_junctions(graph2)\n",
    "print(len(junctions))\n",
    "\n",
    "batch = []\n",
    "for i, j in enumerate(junctions):\n",
    "    in_edge_vertices = [edge[0] for edge in graph2.get_in_edges(j)]\n",
    "    out_edge_vertices = [edge[1] for edge in graph2.get_out_edges(j)]\n",
    "    \n",
    "    in_edge_flows = np.stack([flow[edge] for edge in graph2.get_in_edges(j)])\n",
    "    out_edge_flows = np.stack([flow[edge] for edge in graph2.get_out_edges(j)])\n",
    "    log_offset_ratio = np.log(in_edge_flows.sum()) - np.log(out_edge_flows.sum())\n",
    "\n",
    "    # Balance flows before fitting.\n",
    "    in_edge_flows = np.exp(np.log(in_edge_flows) - log_offset_ratio / 2)\n",
    "    out_edge_flows = np.exp(np.log(out_edge_flows) + log_offset_ratio / 2)\n",
    "    \n",
    "    n, m = len(in_edge_vertices), len(out_edge_vertices)\n",
    "    if n * m > 20:\n",
    "        print(f\"[junc={j} / {n}x{m}] Too many possible paths.\")\n",
    "        continue\n",
    "    X = sz.deconvolution.design_paths(n, m)[0]\n",
    "    fit, paths, named_paths, score_margin = sz.deconvolution.deconvolve_junction(\n",
    "        in_edge_vertices,\n",
    "        in_edge_flows,\n",
    "        out_edge_vertices,\n",
    "        out_edge_flows,\n",
    "        model=sz.depth_model,\n",
    "        forward_stop=0,\n",
    "        backward_stop=0,\n",
    "        alpha=1.,\n",
    "    )\n",
    "    if not (score_margin > 20):  # TODO: Consider selecting non-best models that have a small enough score margin, after using a more negative backward_stop threshold.\n",
    "        print(f\"[junc={j} / {n}x{m}] Cannot pick best model. (Selected model had {len(paths)} paths; score margin: {score_margin})\")\n",
    "    elif not X[:, paths].sum(1).min() == 1:\n",
    "        print(f\"[junc={j} / {n}x{m}] Non-complete. (Best model had {len(paths)} paths; score margin: {score_margin})\")\n",
    "    elif not len(paths) <= max(n, m):\n",
    "        print(f\"[junc={j} / {n}x{m}] Non-minimal. (Best model had {len(paths)} paths; score margin: {score_margin})\")\n",
    "    elif not (np.linalg.cond(fit.hessian_beta) < 1e5):\n",
    "        print(f\"[junc={j} / {n}x{m}] Non-identifiable. (Best model had {len(paths)} paths; score margin: {score_margin})\")\n",
    "    else:\n",
    "        print(f\"[junc={j} / {n}x{m}] SUCCESS! Selected {len(paths)} paths; score margin: {score_margin}\")\n",
    "        batch.append((j, named_paths, {\"path_depths\": fit.beta.clip(0)}))\n",
    "\n",
    "print(len(batch) / len(junctions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_new_tigs = gm.batch_unzip(graph2, *batch)\n",
    "print(len(_new_tigs))\n",
    "\n",
    "_new_tigs = gm.batch_press(graph2, *[(path, {}) for path in sz.assembly.iter_maximal_unitig_paths(graph2)])\n",
    "len(_new_tigs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz.stats.degree_stats(graph2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembly_stage = 4\n",
    "\n",
    "# Calculate Flows\n",
    "flow = []\n",
    "for sample_id in range(graph2.gp['num_samples']):\n",
    "    one_flow, _, _, = sz.flow.estimate_flow(graph2, gt.ungroup_vector_property(graph2.vp['depth'], pos=[sample_id])[0], graph2.vp['length'])\n",
    "    flow.append(one_flow)\n",
    "flow = gt.group_vector_property(flow, pos=range(graph2.gp['num_samples']))\n",
    "\n",
    "# Initial depths\n",
    "plt.hist2d(\n",
    "    graph2.vp['length'].fa,\n",
    "    graph2.vp['depth'].get_2d_array(range(graph2.gp['num_samples'])).sum(0),\n",
    "    bins=(length_bins, depth_bins),\n",
    "    norm=mpl.colors.LogNorm(vmin=1, vmax=1e3),\n",
    ")\n",
    "plt.colorbar()\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.savefig(f'nb/fig/component-{component}/hist_stage{assembly_stage}.pdf')\n",
    "\n",
    "if draw_graphs:\n",
    "    # Update positions\n",
    "    total_bases = graph2.new_vertex_property('float', vals=graph2.vp.length.fa * graph2.vp.depth.get_2d_array(pos=range(graph2.gp['num_samples'])).sum(0))\n",
    "    # sz.draw.update_xypositions(graph2, vweight=total_bases, max_iter=100, init_step=1)\n",
    "\n",
    "    _color = graph2.new_vertex_property('float', vals=graph2.vp['depth'].get_2d_array(range(graph2.gp['num_samples'])).sum(0) ** (1/2))\n",
    "    _width = graph2.new_edge_property('float', vals=flow.get_2d_array(range(graph2.gp['num_samples'])).sum(0) ** (1/2) / 2)\n",
    "    sz.draw.draw_graph(\n",
    "        graph2,\n",
    "        vertex_text=graph2.vp['length'],\n",
    "        vertex_fill_color=_color,\n",
    "        # edge_color=flow,\n",
    "        # edge_pen_width=_width,\n",
    "        output=f'nb/fig/component-{component}/graph_stage{assembly_stage}.pdf',\n",
    "        vcmap=(mpl.cm.magma),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "junctions = sz.assembly.find_junctions(graph2)\n",
    "print(len(junctions))\n",
    "\n",
    "batch = []\n",
    "for i, j in enumerate(junctions):\n",
    "    in_edge_vertices = [edge[0] for edge in graph2.get_in_edges(j)]\n",
    "    out_edge_vertices = [edge[1] for edge in graph2.get_out_edges(j)]\n",
    "    \n",
    "    in_edge_flows = np.stack([flow[edge] for edge in graph2.get_in_edges(j)])\n",
    "    out_edge_flows = np.stack([flow[edge] for edge in graph2.get_out_edges(j)])\n",
    "    log_offset_ratio = np.log(in_edge_flows.sum()) - np.log(out_edge_flows.sum())\n",
    "\n",
    "    # Balance flows before fitting.\n",
    "    in_edge_flows = np.exp(np.log(in_edge_flows) - log_offset_ratio / 2)\n",
    "    out_edge_flows = np.exp(np.log(out_edge_flows) + log_offset_ratio / 2)\n",
    "    \n",
    "    n, m = len(in_edge_vertices), len(out_edge_vertices)\n",
    "    if n * m > 20:\n",
    "        print(f\"[junc={j} / {n}x{m}] Too many possible paths.\")\n",
    "        continue\n",
    "    X = sz.deconvolution.design_paths(n, m)[0]\n",
    "    fit, paths, named_paths, score_margin = sz.deconvolution.deconvolve_junction(\n",
    "        in_edge_vertices,\n",
    "        in_edge_flows,\n",
    "        out_edge_vertices,\n",
    "        out_edge_flows,\n",
    "        model=sz.depth_model,\n",
    "        forward_stop=0,\n",
    "        backward_stop=0,\n",
    "        alpha=1.,\n",
    "    )\n",
    "    if not (score_margin > 20):  # TODO: Consider selecting non-best models that have a small enough score margin, after using a more negative backward_stop threshold.\n",
    "        print(f\"[junc={j} / {n}x{m}] Cannot pick best model. (Selected model had {len(paths)} paths; score margin: {score_margin})\")\n",
    "    elif not X[:, paths].sum(1).min() == 1:\n",
    "        print(f\"[junc={j} / {n}x{m}] Non-complete. (Best model had {len(paths)} paths; score margin: {score_margin})\")\n",
    "    elif not len(paths) <= max(n, m):\n",
    "        print(f\"[junc={j} / {n}x{m}] Non-minimal. (Best model had {len(paths)} paths; score margin: {score_margin})\")\n",
    "    elif not (np.linalg.cond(fit.hessian_beta) < 1e5):\n",
    "        print(f\"[junc={j} / {n}x{m}] Non-identifiable. (Best model had {len(paths)} paths; score margin: {score_margin})\")\n",
    "    else:\n",
    "        print(f\"[junc={j} / {n}x{m}] SUCCESS! Selected {len(paths)} paths; score margin: {score_margin}\")\n",
    "        batch.append((j, named_paths, {\"path_depths\": fit.beta.clip(0)}))\n",
    "\n",
    "print(len(batch) / len(junctions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_new_tigs = gm.batch_unzip(graph2, *batch)\n",
    "print(len(_new_tigs))\n",
    "\n",
    "_new_tigs = gm.batch_press(graph2, *[(path, {}) for path in sz.assembly.iter_maximal_unitig_paths(graph2)])\n",
    "len(_new_tigs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz.stats.degree_stats(graph2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembly_stage = 5\n",
    "\n",
    "# Calculate Flows\n",
    "flow = []\n",
    "for sample_id in range(graph2.gp['num_samples']):\n",
    "    one_flow, _, _, = sz.flow.estimate_flow(graph2, gt.ungroup_vector_property(graph2.vp['depth'], pos=[sample_id])[0], graph2.vp['length'])\n",
    "    flow.append(one_flow)\n",
    "flow = gt.group_vector_property(flow, pos=range(graph2.gp['num_samples']))\n",
    "\n",
    "# Initial depths\n",
    "plt.hist2d(\n",
    "    graph2.vp['length'].fa,\n",
    "    graph2.vp['depth'].get_2d_array(range(graph2.gp['num_samples'])).sum(0),\n",
    "    bins=(length_bins, depth_bins),\n",
    "    norm=mpl.colors.LogNorm(vmin=1, vmax=1e3),\n",
    ")\n",
    "plt.colorbar()\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.savefig(f'nb/fig/component-{component}/hist_stage{assembly_stage}.pdf')\n",
    "\n",
    "if draw_graphs:\n",
    "    # Update positions\n",
    "    total_bases = graph2.new_vertex_property('float', vals=graph2.vp.length.fa * graph2.vp.depth.get_2d_array(pos=range(graph2.gp['num_samples'])).sum(0))\n",
    "    # sz.draw.update_xypositions(graph2, vweight=total_bases, max_iter=100, init_step=1)\n",
    "\n",
    "    _color = graph2.new_vertex_property('float', vals=graph2.vp['depth'].get_2d_array(range(graph2.gp['num_samples'])).sum(0) ** (1/2))\n",
    "    _width = graph2.new_edge_property('float', vals=flow.get_2d_array(range(graph2.gp['num_samples'])).sum(0) ** (1/2) / 2)\n",
    "    sz.draw.draw_graph(\n",
    "        graph2,\n",
    "        vertex_text=graph2.vp['length'],\n",
    "        vertex_fill_color=_color,\n",
    "        # edge_color=flow,\n",
    "        # edge_pen_width=_width,\n",
    "        output=f'nb/fig/component-{component}/graph_stage{assembly_stage}.pdf',\n",
    "        vcmap=(mpl.cm.magma),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "junctions = sz.assembly.find_junctions(graph2)\n",
    "print(len(junctions))\n",
    "\n",
    "batch = []\n",
    "for i, j in enumerate(junctions):\n",
    "    in_edge_vertices = [edge[0] for edge in graph2.get_in_edges(j)]\n",
    "    out_edge_vertices = [edge[1] for edge in graph2.get_out_edges(j)]\n",
    "    \n",
    "    in_edge_flows = np.stack([flow[edge] for edge in graph2.get_in_edges(j)])\n",
    "    out_edge_flows = np.stack([flow[edge] for edge in graph2.get_out_edges(j)])\n",
    "    log_offset_ratio = np.log(in_edge_flows.sum()) - np.log(out_edge_flows.sum())\n",
    "\n",
    "    # Balance flows before fitting.\n",
    "    in_edge_flows = np.exp(np.log(in_edge_flows) - log_offset_ratio / 2)\n",
    "    out_edge_flows = np.exp(np.log(out_edge_flows) + log_offset_ratio / 2)\n",
    "    \n",
    "    n, m = len(in_edge_vertices), len(out_edge_vertices)\n",
    "    if n * m > 20:\n",
    "        print(f\"[junc={j} / {n}x{m}] Too many possible paths.\")\n",
    "        continue\n",
    "    X = sz.deconvolution.design_paths(n, m)[0]\n",
    "    fit, paths, named_paths, score_margin = sz.deconvolution.deconvolve_junction(\n",
    "        in_edge_vertices,\n",
    "        in_edge_flows,\n",
    "        out_edge_vertices,\n",
    "        out_edge_flows,\n",
    "        model=sz.depth_model,\n",
    "        forward_stop=0,\n",
    "        backward_stop=0,\n",
    "        alpha=1.,\n",
    "    )\n",
    "    if not (score_margin > 20):  # TODO: Consider selecting non-best models that have a small enough score margin, after using a more negative backward_stop threshold.\n",
    "        print(f\"[junc={j} / {n}x{m}] Cannot pick best model. (Selected model had {len(paths)} paths; score margin: {score_margin})\")\n",
    "    elif not X[:, paths].sum(1).min() == 1:\n",
    "        print(f\"[junc={j} / {n}x{m}] Non-complete. (Best model had {len(paths)} paths; score margin: {score_margin})\")\n",
    "    elif not len(paths) <= max(n, m):\n",
    "        print(f\"[junc={j} / {n}x{m}] Non-minimal. (Best model had {len(paths)} paths; score margin: {score_margin})\")\n",
    "    elif not (np.linalg.cond(fit.hessian_beta) < 1e5):\n",
    "        print(f\"[junc={j} / {n}x{m}] Non-identifiable. (Best model had {len(paths)} paths; score margin: {score_margin})\")\n",
    "    else:\n",
    "        print(f\"[junc={j} / {n}x{m}] SUCCESS! Selected {len(paths)} paths; score margin: {score_margin}\")\n",
    "        batch.append((j, named_paths, {\"path_depths\": fit.beta.clip(0)}))\n",
    "\n",
    "print(len(batch) / len(junctions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_new_tigs = gm.batch_unzip(graph2, *batch)\n",
    "print(len(_new_tigs))\n",
    "\n",
    "_new_tigs = gm.batch_press(graph2, *[(path, {}) for path in sz.assembly.iter_maximal_unitig_paths(graph2)])\n",
    "len(_new_tigs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz.stats.degree_stats(graph2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembly_stage = 6\n",
    "\n",
    "# Calculate Flows\n",
    "flow = []\n",
    "for sample_id in range(graph2.gp['num_samples']):\n",
    "    one_flow, _, _, = sz.flow.estimate_flow(graph2, gt.ungroup_vector_property(graph2.vp['depth'], pos=[sample_id])[0], graph2.vp['length'])\n",
    "    flow.append(one_flow)\n",
    "flow = gt.group_vector_property(flow, pos=range(graph2.gp['num_samples']))\n",
    "\n",
    "# Initial depths\n",
    "plt.hist2d(\n",
    "    graph2.vp['length'].fa,\n",
    "    graph2.vp['depth'].get_2d_array(range(graph2.gp['num_samples'])).sum(0),\n",
    "    bins=(length_bins, depth_bins),\n",
    "    norm=mpl.colors.LogNorm(vmin=1, vmax=1e3),\n",
    ")\n",
    "plt.colorbar()\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.savefig(f'nb/fig/component-{component}/hist_stage{assembly_stage}.pdf')\n",
    "\n",
    "if draw_graphs:\n",
    "    # Update positions\n",
    "    total_bases = graph2.new_vertex_property('float', vals=graph2.vp.length.fa * graph2.vp.depth.get_2d_array(pos=range(graph2.gp['num_samples'])).sum(0))\n",
    "    # sz.draw.update_xypositions(graph2, vweight=total_bases, max_iter=100, init_step=1)\n",
    "\n",
    "    _color = graph2.new_vertex_property('float', vals=graph2.vp['depth'].get_2d_array(range(graph2.gp['num_samples'])).sum(0) ** (1/2))\n",
    "    _width = graph2.new_edge_property('float', vals=flow.get_2d_array(range(graph2.gp['num_samples'])).sum(0) ** (1/2) / 2)\n",
    "    sz.draw.draw_graph(\n",
    "        graph2,\n",
    "        vertex_text=graph2.vp['length'],\n",
    "        vertex_fill_color=_color,\n",
    "        # edge_color=flow,\n",
    "        # edge_pen_width=_width,\n",
    "        output=f'nb/fig/component-{component}/graph_stage{assembly_stage}.pdf',\n",
    "        vcmap=(mpl.cm.magma),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "junctions = sz.assembly.find_junctions(graph2)\n",
    "print(len(junctions))\n",
    "\n",
    "batch = []\n",
    "for i, j in enumerate(junctions):\n",
    "    in_edge_vertices = [edge[0] for edge in graph2.get_in_edges(j)]\n",
    "    out_edge_vertices = [edge[1] for edge in graph2.get_out_edges(j)]\n",
    "    \n",
    "    in_edge_flows = np.stack([flow[edge] for edge in graph2.get_in_edges(j)])\n",
    "    out_edge_flows = np.stack([flow[edge] for edge in graph2.get_out_edges(j)])\n",
    "    log_offset_ratio = np.log(in_edge_flows.sum()) - np.log(out_edge_flows.sum())\n",
    "\n",
    "    # Balance flows before fitting.\n",
    "    in_edge_flows = np.exp(np.log(in_edge_flows) - log_offset_ratio / 2)\n",
    "    out_edge_flows = np.exp(np.log(out_edge_flows) + log_offset_ratio / 2)\n",
    "    \n",
    "    n, m = len(in_edge_vertices), len(out_edge_vertices)\n",
    "    if n * m > 20:\n",
    "        print(f\"[junc={j} / {n}x{m}] Too many possible paths.\")\n",
    "        continue\n",
    "    X = sz.deconvolution.design_paths(n, m)[0]\n",
    "    fit, paths, named_paths, score_margin = sz.deconvolution.deconvolve_junction(\n",
    "        in_edge_vertices,\n",
    "        in_edge_flows,\n",
    "        out_edge_vertices,\n",
    "        out_edge_flows,\n",
    "        model=sz.depth_model,\n",
    "        forward_stop=0,\n",
    "        backward_stop=0,\n",
    "        alpha=1.,\n",
    "    )\n",
    "    if not (score_margin > 20):  # TODO: Consider selecting non-best models that have a small enough score margin, after using a more negative backward_stop threshold.\n",
    "        print(f\"[junc={j} / {n}x{m}] Cannot pick best model. (Selected model had {len(paths)} paths; score margin: {score_margin})\")\n",
    "    elif not X[:, paths].sum(1).min() == 1:\n",
    "        print(f\"[junc={j} / {n}x{m}] Non-complete. (Best model had {len(paths)} paths; score margin: {score_margin})\")\n",
    "    elif not len(paths) <= max(n, m):\n",
    "        print(f\"[junc={j} / {n}x{m}] Non-minimal. (Best model had {len(paths)} paths; score margin: {score_margin})\")\n",
    "    elif not (np.linalg.cond(fit.hessian_beta) < 1e5):\n",
    "        print(f\"[junc={j} / {n}x{m}] Non-identifiable. (Best model had {len(paths)} paths; score margin: {score_margin})\")\n",
    "    else:\n",
    "        print(f\"[junc={j} / {n}x{m}] SUCCESS! Selected {len(paths)} paths; score margin: {score_margin}\")\n",
    "        batch.append((j, named_paths, {\"path_depths\": fit.beta.clip(0)}))\n",
    "\n",
    "print(len(batch) / len(junctions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_new_tigs = gm.batch_unzip(graph2, *batch)\n",
    "print(len(_new_tigs))\n",
    "\n",
    "_new_tigs = gm.batch_press(graph2, *[(path, {}) for path in sz.assembly.iter_maximal_unitig_paths(graph2)])\n",
    "len(_new_tigs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz.stats.degree_stats(graph2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembly_stage = 7\n",
    "\n",
    "# Calculate Flows\n",
    "flow = []\n",
    "for sample_id in range(graph2.gp['num_samples']):\n",
    "    one_flow, _, _, = sz.flow.estimate_flow(graph2, gt.ungroup_vector_property(graph2.vp['depth'], pos=[sample_id])[0], graph2.vp['length'])\n",
    "    flow.append(one_flow)\n",
    "flow = gt.group_vector_property(flow, pos=range(graph2.gp['num_samples']))\n",
    "\n",
    "# Initial depths\n",
    "plt.hist2d(\n",
    "    graph2.vp['length'].fa,\n",
    "    graph2.vp['depth'].get_2d_array(range(graph2.gp['num_samples'])).sum(0),\n",
    "    bins=(length_bins, depth_bins),\n",
    "    norm=mpl.colors.LogNorm(vmin=1, vmax=1e3),\n",
    ")\n",
    "plt.colorbar()\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.savefig(f'nb/fig/component-{component}/hist_stage{assembly_stage}.pdf')\n",
    "\n",
    "if draw_graphs:\n",
    "    # Update positions\n",
    "    total_bases = graph2.new_vertex_property('float', vals=graph2.vp.length.fa * graph2.vp.depth.get_2d_array(pos=range(graph2.gp['num_samples'])).sum(0))\n",
    "    # sz.draw.update_xypositions(graph2, vweight=total_bases, max_iter=100, init_step=1)\n",
    "\n",
    "    _color = graph2.new_vertex_property('float', vals=graph2.vp['depth'].get_2d_array(range(graph2.gp['num_samples'])).sum(0) ** (1/2))\n",
    "    _width = graph2.new_edge_property('float', vals=flow.get_2d_array(range(graph2.gp['num_samples'])).sum(0) ** (1/2) / 2)\n",
    "    sz.draw.draw_graph(\n",
    "        graph2,\n",
    "        vertex_text=graph2.vp['length'],\n",
    "        vertex_fill_color=_color,\n",
    "        # edge_color=flow,\n",
    "        # edge_pen_width=_width,\n",
    "        output=f'nb/fig/component-{component}/graph_stage{assembly_stage}.pdf',\n",
    "        vcmap=(mpl.cm.magma),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "junctions = sz.assembly.find_junctions(graph2)\n",
    "print(len(junctions))\n",
    "\n",
    "batch = []\n",
    "for i, j in enumerate(junctions):\n",
    "    in_edge_vertices = [edge[0] for edge in graph2.get_in_edges(j)]\n",
    "    out_edge_vertices = [edge[1] for edge in graph2.get_out_edges(j)]\n",
    "    \n",
    "    in_edge_flows = np.stack([flow[edge] for edge in graph2.get_in_edges(j)])\n",
    "    out_edge_flows = np.stack([flow[edge] for edge in graph2.get_out_edges(j)])\n",
    "    log_offset_ratio = np.log(in_edge_flows.sum()) - np.log(out_edge_flows.sum())\n",
    "\n",
    "    # Balance flows before fitting.\n",
    "    in_edge_flows = np.exp(np.log(in_edge_flows) - log_offset_ratio / 2)\n",
    "    out_edge_flows = np.exp(np.log(out_edge_flows) + log_offset_ratio / 2)\n",
    "    \n",
    "    n, m = len(in_edge_vertices), len(out_edge_vertices)\n",
    "    if n * m > 20:\n",
    "        print(f\"[junc={j} / {n}x{m}] Too many possible paths.\")\n",
    "        continue\n",
    "    X = sz.deconvolution.design_paths(n, m)[0]\n",
    "    fit, paths, named_paths, score_margin = sz.deconvolution.deconvolve_junction(\n",
    "        in_edge_vertices,\n",
    "        in_edge_flows,\n",
    "        out_edge_vertices,\n",
    "        out_edge_flows,\n",
    "        model=sz.depth_model,\n",
    "        forward_stop=0,\n",
    "        backward_stop=0,\n",
    "        alpha=1.,\n",
    "    )\n",
    "    if not (score_margin > 20):  # TODO: Consider selecting non-best models that have a small enough score margin, after using a more negative backward_stop threshold.\n",
    "        print(f\"[junc={j} / {n}x{m}] Cannot pick best model. (Selected model had {len(paths)} paths; score margin: {score_margin})\")\n",
    "    elif not X[:, paths].sum(1).min() == 1:\n",
    "        print(f\"[junc={j} / {n}x{m}] Non-complete. (Best model had {len(paths)} paths; score margin: {score_margin})\")\n",
    "    elif not len(paths) <= max(n, m):\n",
    "        print(f\"[junc={j} / {n}x{m}] Non-minimal. (Best model had {len(paths)} paths; score margin: {score_margin})\")\n",
    "    elif not (np.linalg.cond(fit.hessian_beta) < 1e5):\n",
    "        print(f\"[junc={j} / {n}x{m}] Non-identifiable. (Best model had {len(paths)} paths; score margin: {score_margin})\")\n",
    "    else:\n",
    "        print(f\"[junc={j} / {n}x{m}] SUCCESS! Selected {len(paths)} paths; score margin: {score_margin}\")\n",
    "        batch.append((j, named_paths, {\"path_depths\": fit.beta.clip(0)}))\n",
    "\n",
    "print(len(batch) / len(junctions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_new_tigs = gm.batch_unzip(graph2, *batch)\n",
    "print(len(_new_tigs))\n",
    "\n",
    "_new_tigs = gm.batch_press(graph2, *[(path, {}) for path in sz.assembly.iter_maximal_unitig_paths(graph2)])\n",
    "len(_new_tigs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz.stats.degree_stats(graph2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembly_stage = 8\n",
    "\n",
    "# Calculate Flows\n",
    "flow = []\n",
    "for sample_id in range(graph2.gp['num_samples']):\n",
    "    one_flow, _, _, = sz.flow.estimate_flow(graph2, gt.ungroup_vector_property(graph2.vp['depth'], pos=[sample_id])[0], graph2.vp['length'])\n",
    "    flow.append(one_flow)\n",
    "flow = gt.group_vector_property(flow, pos=range(graph2.gp['num_samples']))\n",
    "\n",
    "# Initial depths\n",
    "plt.hist2d(\n",
    "    graph2.vp['length'].fa,\n",
    "    graph2.vp['depth'].get_2d_array(range(graph2.gp['num_samples'])).sum(0),\n",
    "    bins=(length_bins, depth_bins),\n",
    "    norm=mpl.colors.LogNorm(vmin=1, vmax=1e3),\n",
    ")\n",
    "plt.colorbar()\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.savefig(f'nb/fig/component-{component}/hist_stage{assembly_stage}.pdf')\n",
    "\n",
    "if draw_graphs:\n",
    "    # Update positions\n",
    "    total_bases = graph2.new_vertex_property('float', vals=graph2.vp.length.fa * graph2.vp.depth.get_2d_array(pos=range(graph2.gp['num_samples'])).sum(0))\n",
    "    # sz.draw.update_xypositions(graph2, vweight=total_bases, max_iter=100, init_step=1)\n",
    "\n",
    "    _color = graph2.new_vertex_property('float', vals=graph2.vp['depth'].get_2d_array(range(graph2.gp['num_samples'])).sum(0) ** (1/2))\n",
    "    _width = graph2.new_edge_property('float', vals=flow.get_2d_array(range(graph2.gp['num_samples'])).sum(0) ** (1/2) / 2)\n",
    "    sz.draw.draw_graph(\n",
    "        graph2,\n",
    "        vertex_text=graph2.vp['length'],\n",
    "        vertex_fill_color=_color,\n",
    "        # edge_color=flow,\n",
    "        # edge_pen_width=_width,\n",
    "        output=f'nb/fig/component-{component}/graph_stage{assembly_stage}.pdf',\n",
    "        vcmap=(mpl.cm.magma),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "junctions = sz.assembly.find_junctions(graph2)\n",
    "print(len(junctions))\n",
    "\n",
    "batch = []\n",
    "for i, j in enumerate(junctions):\n",
    "    in_edge_vertices = [edge[0] for edge in graph2.get_in_edges(j)]\n",
    "    out_edge_vertices = [edge[1] for edge in graph2.get_out_edges(j)]\n",
    "    \n",
    "    in_edge_flows = np.stack([flow[edge] for edge in graph2.get_in_edges(j)])\n",
    "    out_edge_flows = np.stack([flow[edge] for edge in graph2.get_out_edges(j)])\n",
    "    log_offset_ratio = np.log(in_edge_flows.sum()) - np.log(out_edge_flows.sum())\n",
    "\n",
    "    # Balance flows before fitting.\n",
    "    in_edge_flows = np.exp(np.log(in_edge_flows) - log_offset_ratio / 2)\n",
    "    out_edge_flows = np.exp(np.log(out_edge_flows) + log_offset_ratio / 2)\n",
    "    \n",
    "    n, m = len(in_edge_vertices), len(out_edge_vertices)\n",
    "    if n * m > 20:\n",
    "        print(f\"[junc={j} / {n}x{m}] Too many possible paths.\")\n",
    "        continue\n",
    "    X = sz.deconvolution.design_paths(n, m)[0]\n",
    "    fit, paths, named_paths, score_margin = sz.deconvolution.deconvolve_junction(\n",
    "        in_edge_vertices,\n",
    "        in_edge_flows,\n",
    "        out_edge_vertices,\n",
    "        out_edge_flows,\n",
    "        model=sz.depth_model,\n",
    "        forward_stop=0,\n",
    "        backward_stop=0,\n",
    "        alpha=1.,\n",
    "    )\n",
    "    if not (score_margin > 20):  # TODO: Consider selecting non-best models that have a small enough score margin, after using a more negative backward_stop threshold.\n",
    "        print(f\"[junc={j} / {n}x{m}] Cannot pick best model. (Selected model had {len(paths)} paths; score margin: {score_margin})\")\n",
    "    elif not X[:, paths].sum(1).min() == 1:\n",
    "        print(f\"[junc={j} / {n}x{m}] Non-complete. (Best model had {len(paths)} paths; score margin: {score_margin})\")\n",
    "    elif not len(paths) <= max(n, m):\n",
    "        print(f\"[junc={j} / {n}x{m}] Non-minimal. (Best model had {len(paths)} paths; score margin: {score_margin})\")\n",
    "    elif not (np.linalg.cond(fit.hessian_beta) < 1e5):\n",
    "        print(f\"[junc={j} / {n}x{m}] Non-identifiable. (Best model had {len(paths)} paths; score margin: {score_margin})\")\n",
    "    else:\n",
    "        print(f\"[junc={j} / {n}x{m}] SUCCESS! Selected {len(paths)} paths; score margin: {score_margin}\")\n",
    "        batch.append((j, named_paths, {\"path_depths\": fit.beta.clip(0)}))\n",
    "\n",
    "print(len(batch) / len(junctions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_new_tigs = gm.batch_unzip(graph2, *batch)\n",
    "print(len(_new_tigs))\n",
    "\n",
    "_new_tigs = gm.batch_press(graph2, *[(path, {}) for path in sz.assembly.iter_maximal_unitig_paths(graph2)])\n",
    "len(_new_tigs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz.stats.degree_stats(graph2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembly_stage = 9\n",
    "\n",
    "# Calculate Flows\n",
    "flow = []\n",
    "for sample_id in range(graph2.gp['num_samples']):\n",
    "    one_flow, _, _, = sz.flow.estimate_flow(graph2, gt.ungroup_vector_property(graph2.vp['depth'], pos=[sample_id])[0], graph2.vp['length'])\n",
    "    flow.append(one_flow)\n",
    "flow = gt.group_vector_property(flow, pos=range(graph2.gp['num_samples']))\n",
    "\n",
    "# Initial depths\n",
    "plt.hist2d(\n",
    "    graph2.vp['length'].fa,\n",
    "    graph2.vp['depth'].get_2d_array(range(graph2.gp['num_samples'])).sum(0),\n",
    "    bins=(length_bins, depth_bins),\n",
    "    norm=mpl.colors.LogNorm(vmin=1, vmax=1e3),\n",
    ")\n",
    "plt.colorbar()\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.savefig(f'nb/fig/component-{component}/hist_stage{assembly_stage}.pdf')\n",
    "\n",
    "if draw_graphs:\n",
    "    # Update positions\n",
    "    total_bases = graph2.new_vertex_property('float', vals=graph2.vp.length.fa * graph2.vp.depth.get_2d_array(pos=range(graph2.gp['num_samples'])).sum(0))\n",
    "    # sz.draw.update_xypositions(graph2, vweight=total_bases, max_iter=100, init_step=1)\n",
    "\n",
    "    _color = graph2.new_vertex_property('float', vals=graph2.vp['depth'].get_2d_array(range(graph2.gp['num_samples'])).sum(0) ** (1/2))\n",
    "    _width = graph2.new_edge_property('float', vals=flow.get_2d_array(range(graph2.gp['num_samples'])).sum(0) ** (1/2) / 2)\n",
    "    sz.draw.draw_graph(\n",
    "        graph2,\n",
    "        vertex_text=graph2.vp['length'],\n",
    "        vertex_fill_color=_color,\n",
    "        # edge_color=flow,\n",
    "        # edge_pen_width=_width,\n",
    "        output=f'nb/fig/component-{component}/graph_stage{assembly_stage}.pdf',\n",
    "        vcmap=(mpl.cm.magma),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "junctions = sz.assembly.find_junctions(graph2)\n",
    "print(len(junctions))\n",
    "\n",
    "batch = []\n",
    "for i, j in enumerate(junctions):\n",
    "    in_edge_vertices = [edge[0] for edge in graph2.get_in_edges(j)]\n",
    "    out_edge_vertices = [edge[1] for edge in graph2.get_out_edges(j)]\n",
    "    \n",
    "    in_edge_flows = np.stack([flow[edge] for edge in graph2.get_in_edges(j)])\n",
    "    out_edge_flows = np.stack([flow[edge] for edge in graph2.get_out_edges(j)])\n",
    "    log_offset_ratio = np.log(in_edge_flows.sum()) - np.log(out_edge_flows.sum())\n",
    "\n",
    "    # Balance flows before fitting.\n",
    "    in_edge_flows = np.exp(np.log(in_edge_flows) - log_offset_ratio / 2)\n",
    "    out_edge_flows = np.exp(np.log(out_edge_flows) + log_offset_ratio / 2)\n",
    "    \n",
    "    n, m = len(in_edge_vertices), len(out_edge_vertices)\n",
    "    if n * m > 20:\n",
    "        print(f\"[junc={j} / {n}x{m}] Too many possible paths.\")\n",
    "        continue\n",
    "    X = sz.deconvolution.design_paths(n, m)[0]\n",
    "    fit, paths, named_paths, score_margin = sz.deconvolution.deconvolve_junction(\n",
    "        in_edge_vertices,\n",
    "        in_edge_flows,\n",
    "        out_edge_vertices,\n",
    "        out_edge_flows,\n",
    "        model=sz.depth_model,\n",
    "        forward_stop=0,\n",
    "        backward_stop=0,\n",
    "        alpha=1.,\n",
    "    )\n",
    "    if not (score_margin > 20):  # TODO: Consider selecting non-best models that have a small enough score margin, after using a more negative backward_stop threshold.\n",
    "        print(f\"[junc={j} / {n}x{m}] Cannot pick best model. (Selected model had {len(paths)} paths; score margin: {score_margin})\")\n",
    "    elif not X[:, paths].sum(1).min() == 1:\n",
    "        print(f\"[junc={j} / {n}x{m}] Non-complete. (Best model had {len(paths)} paths; score margin: {score_margin})\")\n",
    "    elif not len(paths) <= max(n, m):\n",
    "        print(f\"[junc={j} / {n}x{m}] Non-minimal. (Best model had {len(paths)} paths; score margin: {score_margin})\")\n",
    "    elif not (np.linalg.cond(fit.hessian_beta) < 1e5):\n",
    "        print(f\"[junc={j} / {n}x{m}] Non-identifiable. (Best model had {len(paths)} paths; score margin: {score_margin})\")\n",
    "    else:\n",
    "        print(f\"[junc={j} / {n}x{m}] SUCCESS! Selected {len(paths)} paths; score margin: {score_margin}\")\n",
    "        batch.append((j, named_paths, {\"path_depths\": fit.beta.clip(0)}))\n",
    "\n",
    "print(len(batch) / len(junctions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_new_tigs = gm.batch_unzip(graph2, *batch)\n",
    "print(len(_new_tigs))\n",
    "\n",
    "_new_tigs = gm.batch_press(graph2, *[(path, {}) for path in sz.assembly.iter_maximal_unitig_paths(graph2)])\n",
    "len(_new_tigs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz.stats.degree_stats(graph2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembly_stage = 10\n",
    "\n",
    "# Calculate Flows\n",
    "flow = []\n",
    "for sample_id in range(graph2.gp['num_samples']):\n",
    "    one_flow, _, _, = sz.flow.estimate_flow(graph2, gt.ungroup_vector_property(graph2.vp['depth'], pos=[sample_id])[0], graph2.vp['length'])\n",
    "    flow.append(one_flow)\n",
    "flow = gt.group_vector_property(flow, pos=range(graph2.gp['num_samples']))\n",
    "\n",
    "# Initial depths\n",
    "plt.hist2d(\n",
    "    graph2.vp['length'].fa,\n",
    "    graph2.vp['depth'].get_2d_array(range(graph2.gp['num_samples'])).sum(0),\n",
    "    bins=(length_bins, depth_bins),\n",
    "    norm=mpl.colors.LogNorm(vmin=1, vmax=1e3),\n",
    ")\n",
    "plt.colorbar()\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.savefig(f'nb/fig/component-{component}/hist_stage{assembly_stage}.pdf')\n",
    "\n",
    "if draw_graphs:\n",
    "    # Update positions\n",
    "    total_bases = graph2.new_vertex_property('float', vals=graph2.vp.length.fa * graph2.vp.depth.get_2d_array(pos=range(graph2.gp['num_samples'])).sum(0))\n",
    "    # sz.draw.update_xypositions(graph2, vweight=total_bases, max_iter=100, init_step=1)\n",
    "\n",
    "    _color = graph2.new_vertex_property('float', vals=graph2.vp['depth'].get_2d_array(range(graph2.gp['num_samples'])).sum(0) ** (1/2))\n",
    "    _width = graph2.new_edge_property('float', vals=flow.get_2d_array(range(graph2.gp['num_samples'])).sum(0) ** (1/2) / 2)\n",
    "    sz.draw.draw_graph(\n",
    "        graph2,\n",
    "        vertex_text=graph2.vp['length'],\n",
    "        vertex_fill_color=_color,\n",
    "        # edge_color=flow,\n",
    "        # edge_pen_width=_width,\n",
    "        output=f'nb/fig/component-{component}/graph_stage{assembly_stage}.pdf',\n",
    "        vcmap=(mpl.cm.magma),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "junctions = sz.assembly.find_junctions(graph2)\n",
    "print(len(junctions))\n",
    "\n",
    "batch = []\n",
    "for i, j in enumerate(junctions):\n",
    "    in_edge_vertices = [edge[0] for edge in graph2.get_in_edges(j)]\n",
    "    out_edge_vertices = [edge[1] for edge in graph2.get_out_edges(j)]\n",
    "    \n",
    "    in_edge_flows = np.stack([flow[edge] for edge in graph2.get_in_edges(j)])\n",
    "    out_edge_flows = np.stack([flow[edge] for edge in graph2.get_out_edges(j)])\n",
    "    log_offset_ratio = np.log(in_edge_flows.sum()) - np.log(out_edge_flows.sum())\n",
    "\n",
    "    # Balance flows before fitting.\n",
    "    in_edge_flows = np.exp(np.log(in_edge_flows) - log_offset_ratio / 2)\n",
    "    out_edge_flows = np.exp(np.log(out_edge_flows) + log_offset_ratio / 2)\n",
    "    \n",
    "    n, m = len(in_edge_vertices), len(out_edge_vertices)\n",
    "    if n * m > 20:\n",
    "        print(f\"[junc={j} / {n}x{m}] Too many possible paths.\")\n",
    "        continue\n",
    "    X = sz.deconvolution.design_paths(n, m)[0]\n",
    "    fit, paths, named_paths, score_margin = sz.deconvolution.deconvolve_junction(\n",
    "        in_edge_vertices,\n",
    "        in_edge_flows,\n",
    "        out_edge_vertices,\n",
    "        out_edge_flows,\n",
    "        model=sz.depth_model,\n",
    "        forward_stop=0,\n",
    "        backward_stop=0,\n",
    "        alpha=1.,\n",
    "    )\n",
    "    if not (score_margin > 20):  # TODO: Consider selecting non-best models that have a small enough score margin, after using a more negative backward_stop threshold.\n",
    "        print(f\"[junc={j} / {n}x{m}] Cannot pick best model. (Selected model had {len(paths)} paths; score margin: {score_margin})\")\n",
    "    elif not X[:, paths].sum(1).min() == 1:\n",
    "        print(f\"[junc={j} / {n}x{m}] Non-complete. (Best model had {len(paths)} paths; score margin: {score_margin})\")\n",
    "    elif not len(paths) <= max(n, m):\n",
    "        print(f\"[junc={j} / {n}x{m}] Non-minimal. (Best model had {len(paths)} paths; score margin: {score_margin})\")\n",
    "    elif not (np.linalg.cond(fit.hessian_beta) < 1e5):\n",
    "        print(f\"[junc={j} / {n}x{m}] Non-identifiable. (Best model had {len(paths)} paths; score margin: {score_margin})\")\n",
    "    else:\n",
    "        print(f\"[junc={j} / {n}x{m}] SUCCESS! Selected {len(paths)} paths; score margin: {score_margin}\")\n",
    "        batch.append((j, named_paths, {\"path_depths\": fit.beta.clip(0)}))\n",
    "\n",
    "print(len(batch) / len(junctions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_new_tigs = gm.batch_unzip(graph2, *batch)\n",
    "print(len(_new_tigs))\n",
    "\n",
    "_new_tigs = gm.batch_press(graph2, *[(path, {}) for path in sz.assembly.iter_maximal_unitig_paths(graph2)])\n",
    "len(_new_tigs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz.stats.degree_stats(graph2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembly_stage = 11\n",
    "\n",
    "# Calculate Flows\n",
    "flow = []\n",
    "for sample_id in range(graph2.gp['num_samples']):\n",
    "    one_flow, _, _, = sz.flow.estimate_flow(graph2, gt.ungroup_vector_property(graph2.vp['depth'], pos=[sample_id])[0], graph2.vp['length'])\n",
    "    flow.append(one_flow)\n",
    "flow = gt.group_vector_property(flow, pos=range(graph2.gp['num_samples']))\n",
    "\n",
    "# Initial depths\n",
    "plt.hist2d(\n",
    "    graph2.vp['length'].fa,\n",
    "    graph2.vp['depth'].get_2d_array(range(graph2.gp['num_samples'])).sum(0),\n",
    "    bins=(length_bins, depth_bins),\n",
    "    norm=mpl.colors.LogNorm(vmin=1, vmax=1e3),\n",
    ")\n",
    "plt.colorbar()\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.savefig(f'nb/fig/component-{component}/hist_stage{assembly_stage}.pdf')\n",
    "\n",
    "if draw_graphs:\n",
    "    # Update positions\n",
    "    total_bases = graph2.new_vertex_property('float', vals=graph2.vp.length.fa * graph2.vp.depth.get_2d_array(pos=range(graph2.gp['num_samples'])).sum(0))\n",
    "    # sz.draw.update_xypositions(graph2, vweight=total_bases, max_iter=100, init_step=1)\n",
    "\n",
    "    _color = graph2.new_vertex_property('float', vals=graph2.vp['depth'].get_2d_array(range(graph2.gp['num_samples'])).sum(0) ** (1/2))\n",
    "    _width = graph2.new_edge_property('float', vals=flow.get_2d_array(range(graph2.gp['num_samples'])).sum(0) ** (1/2) / 2)\n",
    "    sz.draw.draw_graph(\n",
    "        graph2,\n",
    "        vertex_text=graph2.vp['length'],\n",
    "        vertex_fill_color=_color,\n",
    "        # edge_color=flow,\n",
    "        # edge_pen_width=_width,\n",
    "        output=f'nb/fig/component-{component}/graph_stage{assembly_stage}.pdf',\n",
    "        vcmap=(mpl.cm.magma),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORKHERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_results0 = sz.results.extract_vertex_data(graph2).assign(assembly=lambda d: d.segments.apply(sz.results.assemble_overlapping_unitigs, unitig_to_sequence=seqs, k=graph2.gp['kmer_length']))\n",
    "# vertex_results = sz.results.deduplicate_vertex_data(vertex_results0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Low depth\n",
    "vertex_results0[lambda x: (x.total_depth < 10) & (x.total_depth > 2)].sort_values('length', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find cycles\n",
    "vertex_results0[vertex_results0.apply(lambda d: (d.name in d.in_neighbors) | (d.name in d.out_neighbors), axis=1)].sort_values('num_segments', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembly_stage = '_final'\n",
    "v = 202452\n",
    "\n",
    "print(v)\n",
    "print(graph2.vp.length[v])\n",
    "print(graph2.vp.depth[v])\n",
    "print(graph2.vp.sequence[v])\n",
    "print()\n",
    "\n",
    "sns.heatmap(depth_table.sel(unitig=[int(s[:-1]) for s in graph2.vp.sequence[v].split(',')]).to_pandas().T, norm=mpl.colors.SymLogNorm(1e-1))\n",
    "\n",
    "# Flag nodes in sequence v\n",
    "in_seq = graph4.new_vertex_property('bool', val=False)\n",
    "gt.map_property_values(graph4.vp.sequence, in_seq, lambda x: x in graph2.vp.sequence[v].split(','))\n",
    "\n",
    "one_depth = graph4.new_vertex_property('float', graph4.vp['depth'].get_2d_array(pos=range(graph4.gp['num_samples'])).mean(0))\n",
    "one_flow, _, _, = sz.flow.estimate_flow(graph4, one_depth, graph4.vp['length'])\n",
    "_color = graph4.new_vertex_property('float', vals=np.sqrt(one_depth.a))\n",
    "\n",
    "if draw_graphs:\n",
    "    outpath = f'nb/fig/component-{component}/graph_stage{assembly_stage}_seq{v}_id.pdf'\n",
    "    print(outpath)\n",
    "    sz.draw.draw_graph(\n",
    "        graph4,\n",
    "        vertex_text=graph4.vp['sequence'],\n",
    "        vertex_halo=in_seq,\n",
    "        # vertex_text=in_seq,\n",
    "        vertex_font_size=1,\n",
    "        vertex_fill_color=_color,\n",
    "        edge_pen_width=graph4.new_edge_property('float', vals=one_flow.a ** (1/5)),\n",
    "        output=outpath,\n",
    "        vcmap=(mpl.cm.magma, 1),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_results0.segments.explode().value_counts().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = \"71703-\"  # Focal segment/unitig\n",
    "# Get list of sequences with segment u\n",
    "vertex_list = idxwhere(vertex_results0.segments.apply(lambda x: u in x))\n",
    "unitigs = [int(s[:-1]) for s in chain(*vertex_results0.loc[vertex_list].segments)]\n",
    "\n",
    "d = depth_table.sel(unitig=unitigs).to_pandas().T\n",
    "sns.clustermap(d, norm=mpl.colors.SymLogNorm(1e-1))\n",
    "\n",
    "path = f'nb/fig/component-{component}/seqs_stage_final_node{u}.fn'\n",
    "with open(path, 'w') as f:\n",
    "    for vertex, d1 in vertex_results0.loc[vertex_list].iterrows():\n",
    "        print(f\">{vertex}\\n{d1.assembly}\", file=f)\n",
    "print(path)\n",
    "\n",
    "vertex_results0.loc[vertex_list]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "assembly_stage = '_final'\n",
    "\n",
    "# Flag assembled sequences with component u\n",
    "u = \"1744504+\"\n",
    "has_specific_component = graph2.new_vertex_property('bool')\n",
    "gt.map_property_values(graph2.vp.sequence, has_specific_component, lambda x: u in [v for v in x.split(',')])\n",
    "\n",
    "one_depth = graph2.new_vertex_property('float', graph2.vp['depth'].get_2d_array(pos=range(graph2.gp['num_samples'])).sum(0))\n",
    "one_flow, _, _, = sz.flow.estimate_flow(graph2, one_depth, graph2.vp['length'])\n",
    "_color = graph2.new_vertex_property('float', vals=np.sqrt(one_depth.a))\n",
    "\n",
    "if draw_graphs:\n",
    "    outpath = f'nb/fig/component-{component}/graph_stage{assembly_stage}_node{u}.pdf'\n",
    "    print(outpath)\n",
    "    sz.draw.draw_graph(\n",
    "        graph2,\n",
    "        vertex_text=graph2.vp['length'],\n",
    "        vertex_halo=has_specific_component,\n",
    "        # vertex_text=in_seq,\n",
    "        vertex_fill_color=_color,\n",
    "        edge_pen_width=graph2.new_edge_property('float', vals=one_flow.a ** (1/5)),\n",
    "        output=outpath,\n",
    "        vcmap=(mpl.cm.magma, 1),\n",
    "    )\n",
    "\n",
    "print(np.where(has_specific_component.a)[0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "path = f'nb/fig/component-{component}/seqs_stage{assembly_stage}_node{u}.fn'\n",
    "print(path)\n",
    "\n",
    "seen_segment_string = set()\n",
    "\n",
    "with open(path, 'w') as f:\n",
    "    for seq in np.where(has_specific_component.a)[0]:\n",
    "        accum = \"\"\n",
    "        segment_str = graph2.vp.sequence[seq]\n",
    "        for segment in segment_str.split(','):\n",
    "            # print(segment)\n",
    "            seqidx, strand = segment[:-1], segment[-1:]\n",
    "            forward_segment = seqs[seqidx]\n",
    "            # print(len(forward_segment))\n",
    "            if strand == '+':\n",
    "                accum = accum[:-(k - 1)] + forward_segment\n",
    "            else:\n",
    "                accum = accum[:-(k - 1)] + sz.sequence.reverse_complement(forward_segment)\n",
    "\n",
    "        in_neighbors = graph2.get_in_neighbors(seq)\n",
    "        out_neighbors = graph2.get_out_neighbors(seq)\n",
    "        print(seq, segment_str, len(accum), f\"{in_neighbors} X {out_neighbors}\", sep='\\t')\n",
    "        if segment_str in seen_segment_string:\n",
    "            continue\n",
    "        else:\n",
    "            print(f\">{seq}\\n{accum}\", file=f)\n",
    "            seen_segment_string |= {segment_str}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "d = pd.DataFrame(graph2.vp.depth.get_2d_array(pos=range(graph2.gp['num_samples']))[:,np.where(has_specific_component.fa)[0]], columns=np.where(has_specific_component.a)[0])\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(d, norm=mpl.colors.SymLogNorm(1e-2), xticklabels=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "strainzip",
   "language": "python",
   "name": "strainzip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}